{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGsLyLDZduLYHuZz0nYTFI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UmarBalak/Federated-Learning-with-TensorFlow/blob/main/FL_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_federated"
      ],
      "metadata": {
        "id": "6O6AHQjd5DpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "H0DfI-Xe45Qt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Load MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize and reshape\n",
        "x_train = x_train.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "x_test = x_test.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "# Split training data into two parts\n",
        "x_train1, x_train2, x_train3, x_train4 = np.split(x_train, 4)\n",
        "y_train1, y_train2, y_train3, y_train4 = np.split(y_train, 4)\n",
        "\n",
        "NUM_CLIENTS = 10\n",
        "\n",
        "# Function to split data among clients\n",
        "def split_data_among_clients(x_data, y_data):\n",
        "    client_data = []\n",
        "    data_per_client = len(x_data) // NUM_CLIENTS\n",
        "    for i in range(NUM_CLIENTS):\n",
        "        start = i * data_per_client\n",
        "        end = start + data_per_client\n",
        "        client_data.append((x_data[start:end], y_data[start:end]))\n",
        "    return client_data\n",
        "\n",
        "# Create a TFF dataset for each client\n",
        "def create_tf_dataset_for_client(data):\n",
        "    x, y = data\n",
        "    return tf.data.Dataset.from_tensor_slices((x, y)).batch(32)\n",
        "\n",
        "# Split training data among clients\n",
        "client_data1 = split_data_among_clients(x_train1, y_train1)\n",
        "federated_train_data1 = [create_tf_dataset_for_client(client_data1[i]) for i in range(NUM_CLIENTS)]\n",
        "\n",
        "client_data2 = split_data_among_clients(x_train2, y_train2)\n",
        "federated_train_data2 = [create_tf_dataset_for_client(client_data2[i]) for i in range(NUM_CLIENTS)]\n",
        "\n",
        "client_data3 = split_data_among_clients(x_train3, y_train3)\n",
        "federated_train_data3 = [create_tf_dataset_for_client(client_data3[i]) for i in range(NUM_CLIENTS)]\n",
        "\n",
        "client_data4 = split_data_among_clients(x_train4, y_train4)\n",
        "federated_train_data4 = [create_tf_dataset_for_client(client_data4[i]) for i in range(NUM_CLIENTS)]"
      ],
      "metadata": {
        "id": "Y_T7WAaD4_-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions and models"
      ],
      "metadata": {
        "id": "kG-v5ljJ5Gxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_keras_model():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(32, activation='relu'))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "class MulticlassMetrics(tf.keras.metrics.Metric):\n",
        "    def __init__(self, name='multiclass_metrics', **kwargs):\n",
        "        super(MulticlassMetrics, self).__init__(name=name, **kwargs)\n",
        "        self.tp = self.add_weight(name='tp', initializer='zeros')\n",
        "        self.fp = self.add_weight(name='fp', initializer='zeros')\n",
        "        self.fn = self.add_weight(name='fn', initializer='zeros')\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        y_pred = tf.argmax(y_pred, axis=-1)\n",
        "        y_true = tf.cast(y_true, 'int64')\n",
        "\n",
        "        tp = tf.cast(tf.equal(y_true, y_pred), 'float32')\n",
        "        fp = tf.cast(tf.logical_and(tf.not_equal(y_true, y_pred), tf.equal(y_pred, 1)), 'float32')\n",
        "        fn = tf.cast(tf.logical_and(tf.not_equal(y_true, y_pred), tf.equal(y_true, 1)), 'float32')\n",
        "\n",
        "        if sample_weight is not None:\n",
        "            sample_weight = tf.cast(sample_weight, 'float32')\n",
        "            tp = tf.multiply(tp, sample_weight)\n",
        "            fp = tf.multiply(fp, sample_weight)\n",
        "            fn = tf.multiply(fn, sample_weight)\n",
        "\n",
        "        self.tp.assign_add(tf.reduce_sum(tp))\n",
        "        self.fp.assign_add(tf.reduce_sum(fp))\n",
        "        self.fn.assign_add(tf.reduce_sum(fn))\n",
        "\n",
        "    def result(self):\n",
        "        precision = tf.divide(self.tp, self.tp + self.fp + tf.keras.backend.epsilon())\n",
        "        recall = tf.divide(self.tp, self.tp + self.fn + tf.keras.backend.epsilon())\n",
        "        f1_score = 2 * precision * recall / (precision + recall + tf.keras.backend.epsilon())\n",
        "        return [precision, recall, f1_score]\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.tp.assign(0.)\n",
        "        self.fp.assign(0.)\n",
        "        self.fn.assign(0.)\n",
        "\n",
        "def model_fn():\n",
        "    keras_model = create_keras_model()\n",
        "    return tff.learning.models.from_keras_model(\n",
        "        keras_model,\n",
        "        input_spec=federated_train_data1[0].element_spec,\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=[\n",
        "            tf.keras.metrics.SparseCategoricalAccuracy(),\n",
        "            MulticlassMetrics()\n",
        "        ]\n",
        "    )"
      ],
      "metadata": {
        "id": "H_UoxH_T5NJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FL Training"
      ],
      "metadata": {
        "id": "USeO0yiT5PT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build federated training and evaluation processes\n",
        "iterative_process  = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    model_fn,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
        "    )\n",
        "\n",
        "# Initialize federated learning state\n",
        "state = iterative_process.initialize()"
      ],
      "metadata": {
        "id": "27pCUccz6DGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_ROUNDS = 3\n",
        "\n",
        "def evaluate_model(iterative_process, state, model_fn, x_test, y_test):\n",
        "    evaluation_process = tff.learning.algorithms.build_fed_eval(model_fn)\n",
        "    evaluation_state = evaluation_process.initialize()\n",
        "    model_weights = iterative_process.get_model_weights(state)\n",
        "    evaluation_state = evaluation_process.set_model_weights(evaluation_state, model_weights)\n",
        "\n",
        "    federated_test_data = [create_tf_dataset_for_client((x_test, y_test))]\n",
        "    evaluation_output = evaluation_process.next(evaluation_state, federated_test_data)\n",
        "\n",
        "    client_metrics = evaluation_output.metrics['client_work']['eval']['current_round_metrics']\n",
        "    round_loss = client_metrics['loss']\n",
        "    round_accuracy = client_metrics['sparse_categorical_accuracy']\n",
        "    round_precision = client_metrics['multiclass_metrics'][0]\n",
        "    round_recall = client_metrics['multiclass_metrics'][1]\n",
        "    round_f1_score = client_metrics['multiclass_metrics'][2]\n",
        "\n",
        "    print(f'Evaluation on entire test set: Loss={round_loss:.4f}, Accuracy={round_accuracy:.4f}, Precision={round_precision:.4f}, Recall={round_recall:.4f}, F1 Score={round_f1_score:.4f}')\n",
        "\n",
        "    return client_metrics\n",
        "\n",
        "\n",
        "########################### 1st Training and evaluation ####################################\n",
        "for round_num in range(NUM_ROUNDS):\n",
        "    state, metrics = iterative_process.next(state, federated_train_data1)\n",
        "    print(f'Round {round_num+1} on part 1: Loss={metrics[\"client_work\"][\"train\"][\"loss\"]:.4f}, Accuracy={metrics[\"client_work\"][\"train\"][\"sparse_categorical_accuracy\"]:.4f}')\n",
        "\n",
        "eval_metrics = evaluate_model(iterative_process, state, model_fn, x_test, y_test)\n",
        "\n",
        "########################### 2nd Training and evaluation ####################################\n",
        "for round_num in range(NUM_ROUNDS):\n",
        "    state, metrics = iterative_process.next(state, federated_train_data2)\n",
        "    print(f'Round {round_num+1} on part 2: Loss={metrics[\"client_work\"][\"train\"][\"loss\"]:.4f}, Accuracy={metrics[\"client_work\"][\"train\"][\"sparse_categorical_accuracy\"]:.4f}')\n",
        "\n",
        "eval_metrics = evaluate_model(iterative_process, state, model_fn, x_test, y_test)\n",
        "\n",
        "########################### 3rd Training and evaluation ####################################\n",
        "for round_num in range(NUM_ROUNDS):\n",
        "    state, metrics = iterative_process.next(state, federated_train_data3)\n",
        "    print(f'Round {round_num+1} on part 3: Loss={metrics[\"client_work\"][\"train\"][\"loss\"]:.4f}, Accuracy={metrics[\"client_work\"][\"train\"][\"sparse_categorical_accuracy\"]:.4f}')\n",
        "\n",
        "eval_metrics = evaluate_model(iterative_process, state, model_fn, x_test, y_test)\n",
        "\n",
        "########################### 4th Training and evaluation ####################################\n",
        "for round_num in range(NUM_ROUNDS):\n",
        "    state, metrics = iterative_process.next(state, federated_train_data4)\n",
        "    print(f'Round {round_num+1} on part 4: Loss={metrics[\"client_work\"][\"train\"][\"loss\"]:.4f}, Accuracy={metrics[\"client_work\"][\"train\"][\"sparse_categorical_accuracy\"]:.4f}')\n",
        "\n",
        "eval_metrics = evaluate_model(iterative_process, state, model_fn, x_test, y_test)\n"
      ],
      "metadata": {
        "id": "DQbuiwgB6ism"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}